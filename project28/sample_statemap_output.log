QLearningAgent {learningRate = 0.1, discountFactor = 0.9, explorationStart = 1.0, explorationEnd = 1.0e-2, numEpisodes = 100}
S#   
 ### 
   # 
## ##
    G
Start(0,0) Goal(4,4)
Learned Path:
(0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (4, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (3, 2) -> (4, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 2) -> (3, 2) -> (4, 2) -> (3, 2) -> (4, 2) -> (3, 2) -> (4, 2) -> (4, 3) -> (4, 2) -> (3, 2) -> (4, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 1) -> (4, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (0, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (2, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 1) -> (4, 0) -> (4, 1) -> (4, 0) -> (4, 1) -> (4, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 0) -> (2, 1) -> (2, 2) -> (2, 1) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 1) -> (4, 0) -> (4, 1) -> (4, 0) -> (4, 1) -> (4, 2) -> (4, 3) -> (4, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 1) -> (4, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 1) -> (4, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 3) -> (4, 2) -> (4, 1) -> (4, 0) -> (4, 1) -> (4, 0) -> (4, 1) -> (4, 2) -> (4, 1) -> (4, 2) -> (4, 1) -> (4, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 1) -> (4, 2) -> (3, 2) -> (4, 2) -> (4, 3) -> (4, 2) -> (4, 1) -> (4, 2) -> (3, 2) -> (4, 2) -> (3, 2) -> (2, 2) -> (2, 1) -> (2, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 3) -> Goal!
Number of steps: 751
Total reward: -4367.0
The average reward is: 40.68
The average steps is: 17.03
Learned Path:
(0, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 3) -> Goal!
Number of steps: 8
Total reward: 93.0
Learned Path:
(0, 0) -> (1, 0) -> (2, 0) -> (2, 1) -> (2, 2) -> (3, 2) -> (4, 2) -> (4, 3) -> Goal!
Number of steps: 8
Total reward: 93.0